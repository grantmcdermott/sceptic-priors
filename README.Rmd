---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Skeptic priors and climate consensus

<!-- badges: start -->
<!-- badges: end -->

This repository contains code and data for McDermott (2021), ["Skeptic priors and climate consensus"](https://doi.org/10.1007/s10584-021-03089-x). 

> **Abstract:** 
  How much evidence would it take to convince climate skeptics that they are 
  wrong? I explore this question within an empirical Bayesian framework. I 
  consider a group of stylised skeptics and examine how these individuals 
  rationally update their beliefs in the face of ongoing climate change. I find 
  that available evidence in the form of instrumental climate data tends to 
  overwhelm all but the most extreme priors. Most skeptics form updated beliefs 
  about climate sensitivity that correspond closely to estimates from the 
  scientific literature. However, belief convergence is a non-linear function of 
  prior strength and it becomes increasingly difficult to convince the 
  remaining pool of dissenters. I discuss the necessary conditions for consensus
  formation under Bayesian learning and show that apparent deviations from the
  Bayesian ideal can still be accommodated within the same conceptual framework. 
  I argue that a generalized Bayesian model provides a bridge between 
  competing theories of climate skepticism as a social phenomenon.

Click on the green "Code" button above to clone or download the repo to your local computer. Alternately, click on the "fork" button at the very top right of the page to create an independent copy of the repo within your own GitHub account.

## Reproducibility

I use [**Make**](https://www.gnu.org/software/make/) to automate the entire project. Assuming that you have installed Make and have met all of the other dependencies &mdash; see [below](#dependencies) &mdash; the **TL;DR** version for reproducing everything is:

```sh
## Run these commands in the shell
git clone git@github.com:grantmcdermott/skeptic-priors.git
cd skeptic-priors
make
```

You can also limit the build to subsections of the project by passing Make a relevant meta target, e.g.

- `make data` will construct the dataset
- `make main` will run the main analysis
- `make sensitivity` will run all of the sensitivity analyses
- `make paper` will build the paper PDF and SM
- etc.

See the [Makefile](Makefile) to get a sense of the options. The associated DAG is [here](makefile-dag.png) (warning: it's complicated).

## Dependencies

While the entire project can be reproduced via a single call to `make`, users must first satisfy various software dependencies. There are two options: 

1. [`Manual configuration`](#manual-configuration) 
2. [`Docker`](#docker)

### Manual configuration

#### Step 1. Install R and R libraries

The majority of the analysis is conducted in the R programming environment. R is free, open-source and available for download [**here**](https://www.r-project.org/). The code has been tested against R version 4.0.2.

Once R is successfully set up on your system, you will need to install a number of external R libraries. I have used [**renv**](https://rstudio.github.io/renv/) to snapshot the project's R environment. To install all of the necessary R libraries, simply open R at the project root (e.g. by clicking on the .Rproj file) and run the following commands:

```r
## Run these commands in R

# renv::init()  ## Only necessary if you didn't clone/open the repo as an RStudio project
renv::restore(confirm = FALSE)
```

#### Step 2. Install CmdStan

The workhorse Bayesian regressions for this project are passed from R to [**CmdStan**](https://mc-stan.org/users/interfaces/cmdstan). This enables the Bayesian MCMC computation to complete much, much faster than it would otherwise. While R and CmdStan are two separate programs, the easiest way to install the latter is from the former. Assuming that you have completed Step 1 above, run the following line from your R console:

```r
## Run this command in R

cmdstanr::install_cmdstan(version = "2.25.0", cores = 2)
```

#### Step 3: Install Julia and Julia libraries

While most of the analysis is conducted in R, I use Julia (version 1.5.0) for the social cost of carbon calculations. Julia too is free, open-source and available for download [**here**](https://julialang.org/). 

This section of code relies primarily on the [MimiPAGE2009.jl](https://github.com/anthofflab/MimiPAGE2009.jl) package, which is itself part of the [**Mimi framework**](https://www.mimiframework.org/Mimi.jl/stable/) for integrated assessment models in Julia. You will first need to register the Mimi family of models with your Julia installation before installing the necessary packages. Simply open up a Julia terminal at the root level of the project (i.e. where the `Project.toml` file is located) and type in the following:

```julia
## Run these commands in Julia

using Pkg  ## Or hit "]" to enter the Pkg REPL directly

Pkg.Registry.add("General")  ## Likely redundant, but just in case
Pkg.Registry.add(RegistrySpec(url = "https://github.com/mimiframework/MimiRegistry.git"))

Pkg.activate(".")
Pkg.instantiate()

Pkg.precompile()  ## Optional
exit()            ## Optional
```
The above code chunk will activate and then instantiate the project's Julia environment, pulling in all of the necessary package versions.

#### Step 4. Optional(ish)

- I use a tiny bit of Python code to extract some [IDL 'save' data](https://pypi.org/project/IDLSave/) as part of the raw data prep process. Assuming that you have cloned my repo as-is and did not delete any of the data files, Make will automatically skip this section and the Python requirement will be moot. Failing that, however, you will need **SciPy**'s [File IO](https://docs.scipy.org/doc/scipy/reference/tutorial/io.html) module. Regular Python users will almost certainly have SciPy installed on their system already. If not, you can install it yourself, e.g. with PyPi or Conda. I strongly recommend that R users go through **reticulate** (see [here](https://rstudio.github.io/reticulate/articles/python_packages.html)). FWIW, I am using Python 3.8.5 and SciPy 1.5.1 at the time of writing.

- The `extrafont` package is used to embed [Fira Sans](https://fonts.google.com/specimen/Fira+Sans) fonts in the figures. Please note that the Fira Sans font family must be installed separately on your system and also requires some minor setup before R recognizes it (instructions [here](https://github.com/wch/extrafont/blob/master/README.md)). However, you can also skip this setup if you want; R's default Arial fonts will be used if Fira Sans is unavailable.


### Docker

For those of you who don't feel like configuring a manual setup, I also provide a Dockerfile that will automatically bundle all of the dependencies and copy across the project files. To build the Docker image locally:

```sh
## Run these commands in the shell

# cd skeptic-priors  ## Only if you aren't already in the project root
docker build --tag skeptic:1.0.0 .
```
This will take a couple of minutes to pull in all of the necessary R and Julia packages, compile CmdStan etc. But, thereafter, the now-built container will be ready and waiting for immediate deployment whenever you want. Run it with:

```sh
docker run -it --rm skeptic:1.0.0
```

You should see something like:

```sh
root@7400ee9f415f:/skeptic-priors# 
```

You should now be able to run all of the regular Make commands on the project (`make`, `make paper`, etc.), run the individual R scripts (in the `R/` subdir), or generally explore as you wish. 

To stop the container, just type `exit`.

**Aside 1:** Running `make` in the Docker container will generate a bunch of warning messages to the effect of "warning: overriding recipe for target '&'". This is because the Ubuntu OS on the container is running an older version of Make (version 4.2 vs 4.3). It's a bit annoying, but should be harmless.

**Aside 2:** If you don't want to work with (ephemeral) project files that were copied over to the container during the build process, but would rather mount the local version of the project (i.e. the files on your computer that you cloned from GitHub) as an external volume, you are obviously free to do so. 

If you are totally unfamiliar with Docker and want to know more, I have a brief tutorial with additional resources [here](https://raw.githack.com/uo-ec510-2020-spring/lectures/master/12-docker/12-docker.html).


## Performance

```{r perf, include = FALSE}
library(data.table)
library(here)
perf = rbindlist(lapply(list.files(here('performance'), full.names = TRUE), fread))
```


The code has been refactored to run all the Bayesian computation through **CmdStan**. This has yielded *considerable* speed gains, to the point that the entire analysis can be completed in under `r ceiling(sum(perf$sec)/60/10)*10` minutes on my [Dell Precision 5530](https://wiki.archlinux.org/index.php?title=Dell_Precision_5530) laptop.<sup id="a1">[1](#f1)</sup> The table below provides a detailed performance record for the different model runs. Note that I am excluding the data preparation and paper production steps, but each of these only takes a few seconds.

```{r perf_tab, echo = FALSE}
ord = data.table(file = list.files(here('R')))
ord[, run := gsub('.R|-sensitivity', '', file)][, file := paste0('`R/', file, '`')]
setcolorder(ord, c('run', 'file'))
ord[, ord := gsub('[[:alpha:]]|-', '', run)][, run := gsub('^.[0-9]-', '', run)]
ord = ord[!grepl('data', run)]

perf[, sec := as.numeric(sprintf('%.2f', sec))]
perf[run=='evid', run := 'evidence'][run=='rec', run := 'recursive']
perf = ord[perf, on = 'run']
rm(ord)
setorder(perf, ord); perf[, ord:=NULL]
perf[, run2 := fcase(run=='alt-gmst', 'Alternative GMST series',
										 run=='anthro', 'Anthrogenic forcings separate',
										 run=='eff', 'Adjusted forcings efficacies',
										 run=='me-forcings', 'Measurement error in forcings',
										 run=='me-gmst', 'Measurement error in GMST')]
perf[!is.na(run2), run := paste(run2, '(sensitivity)')]
perf[is.na(run2), run := stringr::str_to_title(run)]
perf[, run2 := NULL]
names(perf) = c('Run', 'File', 'Time (sec)', 'Cores used', 'RAM', 'OS', 'Architecture')
knitr::kable(perf)
```


## Problems

If you have any trouble running the code, or find any errors, please file an issue on this repo and I'll look into it.

## License

The software code contained within this repository is made available under the [MIT license](http://opensource.org/licenses/mit-license.php). The data and figures are made available under the [Creative Commons Attribution 4.0 license](https://creativecommons.org/licenses/by/4.0/).

<sup><b id="f1">1</b></sup> Previous versions of the code took a whole day to complete on a cloud server. So you'll understand my being pleased by this improvement. [↩](#a1)